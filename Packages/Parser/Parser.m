(* ::Package:: *)

(* Autogenerated Package *)

ConstructParserObject::usage="";
ParseStream::usage="";
ApplyParser::usage="";


Begin["`Private`"];


(* ::Subsubsection::Closed:: *)
(*ConstructParserObject*)



(* ::Subsubsubsection::Closed:: *)
(*normalizeTokenHandler*)



normalizeTokenHandler[{a_String, b_String}]:=
  {
    Join[
      normalizeTokenHandler[a],
      <|
        "TokenType"->"BlockOpener",
        "BlockType"->{"Delimited", a, b}
        |>
      ],
    Join[
      normalizeTokenHandler[b],
      <|
        "TokenType"->"BlockCloser"
        |>
      ]
    }


normalizeTokenHandler[{a_String, n_Integer}]:=
  Join[
      normalizeTokenHandler[a],
      <|
        "TokenType"->"BlockOpener",
        "BlockType"->{"FixedLength", n}
        |>
      ];


normalizeTokenHandler[a_String]:=
  <|
    "Token"->a,
    "TokenType"->"Atomic",
    "BlockType"->"Infinite",
    "DataFunction"->(#["Body"]&)
    |>


normalizeTokenHandler[a_Association]:=
  Join[
    <|
      "DataFunction"->(#["Body"]&),
      "TokenType"->"Atomic",
      "BlockType"->"Infinite"
      |>,
    a
    ];


(* ::Subsubsubsection::Closed:: *)
(*normalizeTokenHandlers*)



normalizeTokenHandlers[list_List]:=
  Module[{normal=Flatten[normalizeTokenHandler/@list]},
    AssociationThread[
      Lookup[normal, "Token"],
      normal
      ]
    ]


(* ::Subsubsubsection::Closed:: *)
(*ConstructParserObject*)



ConstructParserObject[lexer_, tokenHandlers_]:=
  <|
    "Lexer"->lexer,
    "Handlers"->normalizeTokenHandlers@tokenHandlers
    |>


ConstructParserObject[tokenHandlers_]:=
  Module[{toks=normalizeTokenHandlers@tokenHandlers},
    <|
      "Lexer"->LexerObject[Keys[toks]],
      "Handlers"->toks
      |>
    ]


(* ::Subsubsection::Closed:: *)
(*handleToken*)



(* ::Text:: *)
(*
If we\[CloseCurlyQuote]ve hit a block opener like {
then we want to create a new node that\[CloseCurlyQuote]ll be inserted into the previous one after the block has been built

If we\[CloseCurlyQuote]ve hit a block closer like }
then we want to close out the current node and push it into its parent

If we\[CloseCurlyQuote]ve hit an atomic thing like \[OpenCurlyDoubleQuote]....\[CloseCurlyDoubleQuote] then we want to create and push the node

If we\[CloseCurlyQuote]ve hit a fixed-length node like . (e.g. obj.attr or obj.child.attr)  then we want to keep track of how much we need to look ahead but close off the block after the next complete node

-- Note: I opted to stick this into a BlockType attribute in the parser spec --

There might also be more complex look-ahead type parse nodes though... like we might have want to have . work until a certain token type is hit but keep the body for that one and ditch the rest...?

Or if we see a for (test) { body } we\[CloseCurlyQuote]d really like this to be specifiable as a conditional parse. Like the (test) *must* occur next and then after that we *must* have a {body} node and it should all be captured by the for node...

I guess these can be in the BlockType but as a structured block type? 

There should also be a way for the parser to handle infix type nodes? 
Like a.b.c.e + g.f.g.h should be Plus[Dot[a, b, c, e], Dot[g, f, g, h] but the natural structure from the stream would be Dot[a, b, c, Plus[e, Dot[g, f, g, h]]]. This actually is an issue of Precedence more generally... Can this be resolved in linear time?

*)



handleToken//Clear
handleToken[spec_, next_, node_, blockType_]:=
  Replace[spec["TokenType"],
    {
      "BlockOpener":>
        openNode[spec, next],
      "BlockCloser":>
        closeNode[spec, next, node, blockType],
      "Atomic":>
        closeNode[spec, next, node, blockType]
      }
    ]


(* ::Subsubsubsection::Closed:: *)
(*openNode*)



openNode[spec_, next_]:=
  <|
    "Node"->
      MakeASTNode[
        If[spec["TokenType"]===Automatic, Automatic, "Compound"], 
        spec["DataFunction"]@next,
        next["Token"]
        ],
    "BlockType"->
      spec["BlockType"],
    "ResponseType"->
      "OpenNode"
    |>


(* ::Subsubsubsection::Closed:: *)
(*closeNode*)



(* ::Text:: *)
(*
	This is really where all the AST patterns are defined...
*)



closeNode//Clear
closeNode[spec_, next_, node_, bt:{"Delimited", start_, end_}]:=
  <|
    "Node"->
      AddASTNodeData[node, 
        MakeASTNode["Atomic", spec["DataFunction"]@next, next["Token"]]
        ],
    "BlockType"->bt,
    "ResponseType"->
      If[spec["Token"]=!=end,
        "EditNode",
        "CloseNode"
        ]
    |>;
closeNode[spec_, next_, node_, bt:{"FixedLength", n_}]:=
  <|
    "Node"->
      AddASTNodeData[node, 
        MakeASTNode["Atomic", spec["DataFunction"]@next, next["Token"]]
        ],
    "BlockType"->bt,
    "ResponseType"->
      If[GetASTNodeProperty[node, "ChildCount"]<n-1,
        "EditNode",
        "CloseNode"
        ]
    |>;
closeNode[spec_, next_, node_, bt:"Infinite"]:=
  <|
    "Node"->
      AddASTNodeData[node, 
        MakeASTNode["Atomic", spec["DataFunction"]@next, next["Token"]]
        ],
    "BlockType"->node["BlockType"],
    "ResponseType"->"EditNode"
    |>;
closeNode[spec_, next_, node_, e_]:=
  PackageRaiseException[Automatic, "Invalid block type: ``", e]


(* ::Subsubsection::Closed:: *)
(*ApplyParser*)



(* ::Subsubsubsection::Closed:: *)
(*stack*)



(* ::Text:: *)
(*
	Simple mutable stack type
*)



stack[]:=
  With[{s=Unique[stackVar]}, 
    s = <||>;
    s["Pointer"]=1;
    s["Stack"]=ConstantArray[None, 50];
    stack[s]
    ];
stack[s_]@"Push"[val_]:=
  If[s["Pointer"]==Length@s["Stack"],
    s@"Allocate"[Length@s["Stack"]*2];
    stack[s]@"Push"[val],
    s[["Stack", s["Pointer"]++ ]]=val;
    ];
stack[s_]@"Pop"[]:=
  If[s["Pointer"]==1,
    $Failed,
    (s[["Stack", s["Pointer"] ]]=None;#)&@
      s[["Stack", --s["Pointer"] ]]
    ];
stack~SetAttributes~HoldFirst;


(* ::Subsubsubsection::Closed:: *)
(*continueParse*)



continueParse[handler_, next_]:=
  (!MissingQ[handler])&&(next["Body"]=!=EndOfFile)


(* ::Subsubsubsection::Closed:: *)
(*manageResponse*)



(* ::Text:: *)
(*
	The original idea was basically that a node could open a block, close a block, or be atomic
	Instead, we\[CloseCurlyQuote]re going to move to an operator-precedence parser. This kind of thing can operate fine *if* properly ordered precedences so we\[CloseCurlyQuote]ll call it inside the precedence parser.
*)



manageResponse[{stack_, state_}, resp_, toks_]:=
  Switch[resp["ResponseType"],
    "OpenNode",
      AppendTo[stack, state];
      state["CurrentNode"] = resp["Node"];
      state["BlockType"] = resp["BlockType"],
    "EditNode",
      state["CurrentNode"] = resp["Node"],
    "CloseNode",
      state = stack[[-1]];
      stack = stack[[;;-2]];
      state["CurrentNode"] = AddASTNodeData[state["CurrentNode"], resp["Node"]]
    ];
manageResponse~SetAttributes~HoldFirst;


(* ::Subsubsubsection::Closed:: *)
(*parseExpression*)



(* ::Text:: *)
(*
	This implements our precedence parser. Not elegant but will hopefully get the job done. Presumably each \[OpenCurlyDoubleQuote]Read\[CloseCurlyDoubleQuote] call can be optimized or a faster, less-safe \[OpenCurlyDoubleQuote]Reader\[CloseCurlyDoubleQuote] object can be returned.
*)



parseExpression[{state_, stack_}, handlers_, toks_]:=
  Module[{next, handler, resp},
    next = toks@"Read"[];
    handler = Lookup[handlers, next["Token"]];
    While[continueParse[handler, next],
      resp = handleToken[handler, next, state];
      manageResponse[{state, stack}, resp, toks];
      next = toks@"Read"[];
      handler = Lookup[handlers, next["Token"]];
      ]
    ];
parseExpression~SetAttributes~HoldFirst;


(* ::Subsubsubsection::Closed:: *)
(*ParseStream*)



ParseStream[parser_, stream_]:=
  Module[
    {
      toks = parser["Lexer"]@"TokenStream"[stream],
      handlers = parser["Handlers"],
      ast = ASTObject[],
      state,
      current,
      blockType,
      data,
      next,
      handler,
      stack = {},
      prec,
      resp
      },
    Internal`WithLocalSettings[
      None,
      state["CurrentNode"] = ast["Tree"];
      state["BlockType"] = "Infinite";
      state["Precedence"] = 0;
      parseExpression[{state, stack}, handlers, toks],
      {
        stack,
        InterfaceModify[ASTObject, ast, ReplacePart[#, "Tree"->current]&]
        },
      If[StringQ@stream, toks@"Close"[]]
      ]
    ]


ApplyParser[parser_, stream_]:=
  Module[{stack, ast},
    {stack, ast}=
      Block[{LexerToken = ConstructLexToken}, ParseStream[parser, stream]];
    If[Length@stack>0,
      PackageRaiseException[
        "Incomplete node parse at end of stream"
        ]
      ];
    ast
    ]


End[];



